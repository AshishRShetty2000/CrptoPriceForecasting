{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e4806883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8755db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset the-reddit-dataset-dataset (C:/Users/bibek/.cache/huggingface/datasets/SocialGrep___the-reddit-dataset-dataset/comments/1.0.0/e1425cc8beebba4388da97f897d2f9275f462e1fb78b1bc4f89b5f4276ee2475)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"SocialGrep/the-reddit-dataset-dataset\", \"comments\",split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91dd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()[[\"body\",\"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460a1d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spatial problem: Suitability of new locations ...</td>\n",
       "      <td>0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Have you tried toying around with GDELT or Ali...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Damn random internet person of whom I know not...</td>\n",
       "      <td>-0.3851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah nice one. Best of luck with the baby. If yo...</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was about to write and say this shouldn't be...</td>\n",
       "      <td>0.0762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>See http://code.reddit.com/wiki/API and http:/...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54844</th>\n",
       "      <td>Careful of the licence on this one.</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54845</th>\n",
       "      <td>Also a great example of exposing an API with v...</td>\n",
       "      <td>0.8545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54846</th>\n",
       "      <td>From the overview:\\n\"We have collected packet ...</td>\n",
       "      <td>0.5789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54847</th>\n",
       "      <td>https://developer.yahoo.com/yql/console/?q=SEL...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54848 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  sentiment\n",
       "0      Spatial problem: Suitability of new locations ...     0.0772\n",
       "1      Have you tried toying around with GDELT or Ali...     0.0000\n",
       "2      Damn random internet person of whom I know not...    -0.3851\n",
       "3      Ah nice one. Best of luck with the baby. If yo...     0.9136\n",
       "4      I was about to write and say this shouldn't be...     0.0762\n",
       "...                                                  ...        ...\n",
       "54843  See http://code.reddit.com/wiki/API and http:/...        NaN\n",
       "54844                Careful of the licence on this one.     0.1531\n",
       "54845  Also a great example of exposing an API with v...     0.8545\n",
       "54846  From the overview:\\n\"We have collected packet ...     0.5789\n",
       "54847  https://developer.yahoo.com/yql/console/?q=SEL...        NaN\n",
       "\n",
       "[54848 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74ae1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\n\\n.+?\\n\\n','', text, flags=re.MULTILINE)\n",
    "    # Remove special characters (keeping only letters, numbers, and basic punctuation)\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s,.\\'\"]+', ' ', text)\n",
    "    text = re.sub(r'\\n',' ', text)\n",
    "    text = re.sub(r'n\\'t',' not', text)\n",
    "    text = re.sub(r'\\'m', ' am', text)\n",
    "    text = re.sub(r'\\'s',' is', text)\n",
    "    text = re.sub(r'[\".,\\']+', '', text)\n",
    "    text = \" \".join(text.split())\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fd62161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_sentiment_class(value):\n",
    "    sentiment_class = 0\n",
    "    if(value>0):\n",
    "        sentiment_class = 1\n",
    "    elif(value<0):\n",
    "        sentiment_class = -1\n",
    "    return sentiment_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b13acacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_class'] = df['sentiment'].apply(assign_sentiment_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3718dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text\"] = df[\"body\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd1b23ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'did u ever find this also in a bind for a school project lol i assumed this would be easy to find'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = 133\n",
    "df[\"clean_text\"][row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2d52a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'did u ever find this? also in a bind for a school project lol i assumed this would be easy to find'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"body\"][row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "873833a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment_class'][row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8ac9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99453b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a row is noisy\n",
    "def is_noisy(text, min_word_count=3):\n",
    "    # Check if text is mostly numeric\n",
    "    if re.fullmatch(r'\\d+', text):\n",
    "        return True\n",
    "    # Check if the text has fewer than the minimum word count\n",
    "    if len(text.split()) < min_word_count:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Filter out noisy rows\n",
    "df_cleaned = df[~df['clean_text'].apply(is_noisy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e09e6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47658, 4), (54848, 4))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape,df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc8189b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_cleaned[[\"clean_text\",\"sentiment_class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4448332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spatial problem suitability of new locations f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>have you tried toying around with gdelt or ali...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>damn random internet person of whom i know not...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ah nice one best of luck with the baby if you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was about to write and say this should not b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54841</th>\n",
       "      <td>full list here</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54842</th>\n",
       "      <td>this was posted in another thread</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54844</th>\n",
       "      <td>careful of the licence on this one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54845</th>\n",
       "      <td>also a great example of exposing an api with v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54846</th>\n",
       "      <td>from the overview we have collected packet tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47658 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  sentiment_class\n",
       "0      spatial problem suitability of new locations f...                1\n",
       "1      have you tried toying around with gdelt or ali...                0\n",
       "2      damn random internet person of whom i know not...               -1\n",
       "3      ah nice one best of luck with the baby if you ...                1\n",
       "4      i was about to write and say this should not b...                1\n",
       "...                                                  ...              ...\n",
       "54841                                     full list here                0\n",
       "54842                  this was posted in another thread                0\n",
       "54844                 careful of the licence on this one                1\n",
       "54845  also a great example of exposing an api with v...                1\n",
       "54846  from the overview we have collected packet tra...                1\n",
       "\n",
       "[47658 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b58f92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df, val_df = train_test_split(df_cleaned, test_size=0.3, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a43bcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[:1000]\n",
    "val_df = val_df[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "becf4c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39808</th>\n",
       "      <td>hey u u olegispe i am removing post because it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37199</th>\n",
       "      <td>maybe this dataset england specific though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34452</th>\n",
       "      <td>great since the images of each model can be ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9049</th>\n",
       "      <td>a laptop or laptop computer is a small portabl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19170</th>\n",
       "      <td>there is a dataset from the faa i think you ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>thank you very much can i dm you for some help...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47541</th>\n",
       "      <td>what is the format of the file i was able to d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34586</th>\n",
       "      <td>mental health datasets are notoriously hard to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11766</th>\n",
       "      <td>well even if that thought is true then you d e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49742</th>\n",
       "      <td>yes if that dataset is available but how do yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  sentiment_class\n",
       "39808  hey u u olegispe i am removing post because it...                1\n",
       "37199         maybe this dataset england specific though                0\n",
       "34452  great since the images of each model can be ea...                1\n",
       "9049   a laptop or laptop computer is a small portabl...                1\n",
       "19170  there is a dataset from the faa i think you ca...                0\n",
       "...                                                  ...              ...\n",
       "7207   thank you very much can i dm you for some help...                1\n",
       "47541  what is the format of the file i was able to d...                0\n",
       "34586  mental health datasets are notoriously hard to...                1\n",
       "11766  well even if that thought is true then you d e...                1\n",
       "49742  yes if that dataset is available but how do yo...                1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cbd5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "59fc0959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "batch_size = 16  # You can adjust the batch size based on your available memory\n",
    "dataset_train = TextDataset(train_df['clean_text'].tolist())\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "dataset_val = TextDataset(val_df['clean_text'].tolist())\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd307fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00af4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5bb33c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_embeddings = []\n",
    "# for text in train_df[\"clean_text\"]:\n",
    "#     inputs = tokenizer(text,padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#     # Get the hidden states from the last layer of BERT\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#         cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "#         train_embeddings.extend(cls_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b648501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "185210c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings in batches\n",
    "train_embeddings = []\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader_train:\n",
    "        # Tokenize the batch of sentences at once\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        # Get the [CLS] token embeddings for each sentence in the batch\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "        train_embeddings.extend(cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d4e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cd3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e11372b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_embeddings = []\n",
    "# for text in val_df[\"clean_text\"]:\n",
    "#     inputs = tokenizer(text,padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#     # Get the hidden states from the last layer of BERT\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#         cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "#         val_embeddings.extend(cls_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09e5a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings in batches\n",
    "val_embeddings = []\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader_val:\n",
    "        # Tokenize the batch of sentences at once\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        # Get the [CLS] token embeddings for each sentence in the batch\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "        val_embeddings.extend(cls_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8647ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02997868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bibek\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_embeddings, train_df[\"sentiment_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dee751b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_labels = logreg.predict(val_embeddings)\n",
    "print(\"Validation Accuracy:\", accuracy_score(val_df[\"sentiment_class\"], pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24b2bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b26aa17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an SVC object\n",
    "svm_model = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(train_embeddings, train_df[\"sentiment_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f5c9d79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7133333333333334\n"
     ]
    }
   ],
   "source": [
    "pred_labels = svm_model.predict(val_embeddings)\n",
    "print(\"Validation Accuracy:\", accuracy_score(val_df[\"sentiment_class\"], pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b3412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "513f1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bcb9f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 768  # From your embedding shape\n",
    "hidden_dim = 128  # Adjust as needed\n",
    "output_dim = 3  # Assuming 3 sentiment classes (-1, 0, 1)\n",
    "\n",
    "model = SentimentClassifier(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f308e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(train_embeddings, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_df[\"sentiment_class\"].values + 1, dtype=torch.long)  # Assuming you have sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb50b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a4b49a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 768]), torch.Size([1000]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4ec52626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.4063225984573364\n",
      "Epoch 2/10, Loss: 0.36372947692871094\n",
      "Epoch 3/10, Loss: 0.33103638887405396\n",
      "Epoch 4/10, Loss: 0.30589941143989563\n",
      "Epoch 5/10, Loss: 0.2771449089050293\n",
      "Epoch 6/10, Loss: 0.24609558284282684\n",
      "Epoch 7/10, Loss: 0.2369849979877472\n",
      "Epoch 8/10, Loss: 0.18568888306617737\n",
      "Epoch 9/10, Loss: 0.1628016233444214\n",
      "Epoch 10/10, Loss: 0.12317706644535065\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10  # Adjust as needed\n",
    "batch_size = 16  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a4ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "588cd791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert `val_embeddings` to a PyTorch tensor\n",
    "X_val = torch.tensor(val_embeddings, dtype=torch.float32)\n",
    "\n",
    "# Shift labels to be non-negative (0, 1, 2)\n",
    "y_val = torch.tensor(val_df[\"sentiment_class\"].values + 1, dtype=torch.long)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_val)\n",
    "    _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val.cpu().numpy(), predicted.cpu().numpy())\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0718a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"sentiment_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500322cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
